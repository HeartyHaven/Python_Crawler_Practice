# 实战：获取网易云音乐评论数据
2023.7.1 HAVEN
## 1.引言
网易云音乐的高赞评论中，不乏思想深刻、文笔美妙的，有时会给人思想启发，也会给写作锦上添花。所以就有人想要把网易云音乐一些歌曲的评论批量爬取到本地。

一般情况下，我们要获取数据首先要分析数据从哪里来。我们首先右击浏览器，选择“查看页面源代码”，并在页面代码中检索评论信息，但是很遗憾，并没有。
![源代码找不到评论](/Python_Crawler_Practice-/proj3/imgs/pre1.png)

之后很自然地就会想，那可能是数据在客户端装配，于是用F12抓包，一个个找，终于在一个文件中找到了评论数据。

![找到了评论数据](/Python_Crawler_Practice-/proj3/imgs/pre2.png)

如果这个时候你直接用requests.get获取数据，你会发现你什么都得不到，不仅因为这个请求是post而不是get，更是因为从标头看出它负载了两个参数:params和encSecKey.
我不妨展示一下这两个东西：

`params`:xZuRoYukkK4fSnNNFnBFgObkJQhTnOv79jdLOvzi10NDkhUFAJNiNDBofvyJ5E/CXb55A/0EqiWRjzH8i/nEEXEzO+18dferp3qGJvcbxKaL7nkWs9RjoX7w+T/RT984AO9pOyVEsB3vl/XthZEiB4CxKj9HOJ3JUA0W+L+Exc+FIAihgECzKgZPZlgGG8SDQHdGHKS59CrG1wGKzzJfKakehz/YrGkqSYn/PZi0wC35dLOJq3SUk6LPz2pJ1Dx5EUk/p3egK0m7SGzWhY+qK9I9cxPISYgj0Nu+K8t5f16g0DoVYk4SfJWSinm66y2iGCAkFyhgXitJSnbY7GW0SxQy4LbHL/nRdxDgSpQL9bg=

`encSecKey`:a4f81fe149b5264ab87611c994968def1c54ed8260c4b252d34ad25b60ef9ed45a4ec31abcc656b0c5bbf7bd002e93e4a7f03597ceb3bf01b19ea3d6cd47f325ba3b58af0d6a8c37abdf8676a0b128684927dc5f39cc90eaa5b1afc2f8d2d28dd6bea15b52910cb91ecec6c2c2c6637f8476d54e048755e5beac77894a7bb25a

可以看出，这很明显不是一个人能写出来的东西。当然你可以选择不去考虑这些，直接把这两个东西当作你的请求参数放到你的语句里。这没有问题，结果也能正确呈现。但是，如果你要爬取的歌不止一首，或者说，你要爬取的评论不仅仅是热评，还有最新评论（这代表你需要翻页评论区），你这时候将会访问多次网页，那你就会发现这个方法不灵了。因为，这两个参数在你不同的访问中也是不同的，它们是随机的！

**如果我必须要爬好多页数据，那我必须搞清楚它们是怎么来的，只有这样我才能在本地按照这样的规律自己构造这两个参数，才能不至于在换歌或切换页码的时候重新把参数更新一遍。**
## 2.参数的分析
单从给定的参数形式上看，我们能猜测它们是经过了数据加密才成了这个样子；而数据加密的算法一定写到源程序中了，因为至少这个加密过程是在网页响应我们的请求之后执行的。
**基于此，我们可以从参量经过的程序来回溯，观察到底在哪里进行了数据的加密，原始的数据又是什么样子的。**
只有如此，我们才能搞清楚我们要对什么东西进行加密，怎么进行加密。

首先，我们还是找到评论数据文件请求头，拷贝一下url，这个在之后有用，它还是我们最终构建`requests.post`的目标网址。

在最新的Edge浏览器中，我们在开发者界面能够看到一个叫做“发起程序”的栏目，这个栏目里的“请求调用堆栈”模块中展现了负载参数都经历了哪些程序的洗礼。这些程序以栈的形式堆叠在模块中，越先被调用的程序就越靠下。我们点击最新的（排在最上面的）那个程序，进入到源代码，发现页面会提示我们它目前执行到哪一步停下了（刚刚打开可能看不出来，因为代码格式化可能耽误了，再打开一次就行了）。

![请求调用堆栈](/Python_Crawler_Practice-/proj3/imgs/1.2.png)


我们在这条语句这里设置一个断点，并且刷新网页。我们能惊奇地发现，这条语句被执行了不止一次。每次停下的时候我们点击“恢复脚本执行”，就能看见：每点一次，网页就加载一部分。那么哪一部分是我们要的，请求评论数据的部分呢？

这里我们打开右侧的“作用域”，这里展现了所有参量的值。在这里你仔细翻一翻，就能看见一个类似网址的变量，可能在一个request字典里面，它显示的是目前程序所处的网址。
![request](/Python_Crawler_Practice-/proj3/imgs/1.1.png)


我们监视好这个变量，然后不停地按“恢复脚本执行”，直到这个网址变成我们目标的那个url，停下！我们这时候我们看作用域中的data：

`data`:"params=ZKWQwROZ6eqw2MSZ7EzsIjyrtRXflizK0MYahyzwMKmUlcT7eYrwTbjoWwiojRYUQtrPhCq1q4jTKwMvhAD4pUpE4L5e9hpxfW%2BMbcRmQiqljMBJpjyJ%2BrgS%2FwumoGii
encSecKey=70c9338104690fce0da7092c724e47e7b1bd1db0cacab87039cf05584ea02a1d5df18d1d714087d8231d68bd5a35d25a862d97648dc15c0155ada61637ac5cdc99ab66d01ed59ef3811d1408f4e3e60d5790e7a8c79cd0e63d15f59ae89587943e09479c6ba6febb7c2603595c726cdec847a85de0d76eb8c6f3c84470780d2c"
![第一个大部分](/Python_Crawler_Practice-/proj3/imgs/step1.png)

有没有比较熟悉？哈哈，现在我们就知道了，开头讲的那两个参数原来是这样存放在一个data中，集中送到程序里的。除此之外，我们也得到了一个不幸的消息：我们本来以为，只要在请求评论数据的地方停下，就能够看见原始的数据和加密代码了，但现在，不仅没能看到原数据，代码更是无从谈起。但可以肯定的是，应该离着真相已经比较近了，至少我们已经成功到达了获取评论数据的地方了。

现在要做的，就是回溯，从当前的时间点，一点点往回推，直到我们看见data改变了的时候，那个时候就能判断到底哪里发生了加密了。具体应该怎么做呢？我们看见在源代码界面，还有一个“请求调用堆栈”，这样就方便了：我们不仅能够监视data，又能从上往下地查看程序，以及参数执行完这个程序是什么样子的。接下来只需一个个往回找就可以咯！

![第二个大部分](/Python_Crawler_Practice-/proj3/imgs/step2.png)


然后，如图所示，在我们回溯到这个`(匿名)`程序的时候，data突然变得可读了。我们就找到了未加密的参数：rid=R_SO_4_447926067&threadId=R_SO_4_447926067&pageNo=1&pageSize=20&cursor=-1&offset=0&orderType=1"。
也就是说，在这个`（匿名）`程序结束的时候，所有的数据都是没加密的，但是到这个`u4y.be5j`执行完全结束之后，数据变成加密的了，说明在`u4y.be5j`这里，程序对参数进行了加密。

除此之外，我们还得到一个重要信息：展开作用域中的`i4n`,我们发现，rid,threadId...这些都在data中了！最后仔细比对一下，就能得到结论：**data实际上就是这个i4n，只不过装配成了字符串形式。**
我们也发现，这个`i4n`中有pageNo,curser等有意义的参量，在我们要爬取多条数据的时候，可能只需要在本地修改pageNo就能实现自动翻页。所以我们可以拷贝`i4n`到本地，命名为`data`，它是一个字典。

**下面我们要做的事情是：找到那个加密函数，破案！**

![找函数](/Python_Crawler_Practice-/proj3/imgs/step3.png)

既然这个`u4y.be5j`做了加密，我们就要想办法进入到这个程序里面。我们看见`（匿名）`程序的“最后一条语句”正好是`u4y.be5j`的一个函数的入口，所以我们从这里设置断点。其实也可以在`u4y.be5j`设置断点，但是你真的不好确定它的加密函数到底在哪里：因为我们每次回溯，系统总是只能帮我们停留在这个程序执行的最后一条语句那里，所以我们不知道加密的部分离着这条语句有多远，它们甚至可能不在一个括号里！

设置好断点之后，刷新网页，还是老办法，定位到目标网址url，然后开始放慢速度，在`（匿名）`的最后一条语句，步入到`u4y.be5j`中。然后我们尝试着一步步走（步过），看到哪一步data突然变了。实践之后，可以发现在执行完这个`window.asrsea`之后不过两三条语句，data就变成了密文。

![找到加密部分](/Python_Crawler_Practice-/proj3/imgs/step4.png)

那么具体是怎么回事呢？除了现象，我们还需要证据来确定我们这个猜想是正确的：`window.asrsea`就是我们要找的加密函数。首先，我们看见它后面的语句，即便没有学过JavaScript，我们也能看出来，这个是赋值语句：它把`e4i.data`赋值为一个函数`j4n.cr5w`的返回值：参数是个字典，里面有`params`,`enSecKey`...这不就是咱们刚才看到的`data`里的构成部分嘛！看来这个赋值语句就是把加密结果放回到原data中的部分了，而那个`j4n.cr5w`大概是个把字典转化为字符串的函数吧。

再来分析参数，这个`window.asrsea`里面的第一个参数是`stringify(i4m)`，从字面上，很好理解这是把一个东西变成字符串了，而这个i4m，正好就是我们刚才发现的原始数据的字典形态！那么这个asrsea肯定是拿着我们的原始数据进去做了些什么，返回了一个bVe2x，并重新赋值给data了。这些难道还不足以说明`window.asrsea`就是加密函数吗？
![加密函数](/Python_Crawler_Practice-/proj3/imgs/step5.png)


接下来怎么做呢？当然是要看看`window.asrsea`究竟是何方神圣了。我们直接全局搜索，最终只有2个匹配结果，除去调用的这个部分，另外一个部分很明显就是定义的部分了。
![定位加密函数](/Python_Crawler_Practice-/proj3/imgs/step6.png)

这里有5个函数`a` `b` `c` `d` `e`.仔细观察一下，这个`window.asrsea`被确定为`d`函数，而`d`函数中又用了`a`函数、`b`函数和`c`函数。所以我们就好好看看这四个函数。

    function a(a) {                        
        var d, e, b = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789", c = ""; 
        for (d = 0; a > d; d += 1)
            e = Math.random() * b.length,   
            e = Math.floor(e),              
            c += b.charAt(e)
        return c                            
    }
    function b(a, b) {
        var c = CryptoJS.enc.Utf8.parse(b)               
          , d = CryptoJS.enc.Utf8.parse("0102030405060708")
          , e = CryptoJS.enc.Utf8.parse(a)                  
          , f = CryptoJS.AES.encrypt(e, c, {        
            iv: d,                                         
            mode: CryptoJS.mode.CBC                       
        });
        return f.toString()                                
    }
    function c(a, b, c) {
        var d, e;
        return setMaxDigits(131),
        d = new RSAKeyPair(b,"",c),
        e = encryptedString(d, a)
    }
    function d(d, e, f, g) {           
        var h = {}                      
          , i = a(16);                       
        return h.encText = b(d, g),     
        h.encText = b(h.encText, i),    
        h.encSecKey = c(i, e, f),      
    }
这是从网页源代码中扒下来的Js代码。其中`d`是最核心的代码。它首先声明了一个空字典，然后又获取了一个i，之后对h里面填充了两个属性`encText`、`encSecKey`，这两个属性都通过`b`得到。

一点点分析，咱们先看i是什么。i是`a`生成的。`a`很明显是生成了一个随机的什么东西，所以i是随机的。仔细来看，`a`定义了一个字符表和一个空的字符串c。之后进行了16轮循环，每一轮循环随机生成一个不超过字符表长度的非负整数e,然后把e所在位置对应的那个字符加入到字符串c中。这个函数的执行结果就是一个完全随机生成的16位字符串i。

咱们再看`c`是什么：`c`是对参数进行了一个RSA加密，我们不用仔细研究`c`，具体原因我们稍后说明。

之后，我们看一下b是什么：b指定了一个字符串，并且对参数a,b用utf8进行编码得到了e,c，也就是说其实a与e，b与c是等价的。之后就对它们做了一个AES加密工作，结果在f中返回。

最后，我们回过头看一下函数的参数是什么：对比观察`d`和`window.asrsea`,得到，参数d是我们原始数据转化过来的字符串，后面那三个东西又是啥呢？其实你只需要在开发者工具的调试器试一下，就知道，这三个东西其实都是常量！它们不随网页浏览时机或浏览的网页而变。
![参数说明](/Python_Crawler_Practice-/proj3/imgs/step7.png)
![参数调试](/Python_Crawler_Practice-/proj3/imgs/step8.png)

这样一来，既然e,f,g全部都是常量，我们就能确定了：
- `d`函数实际上只跟第一个参数d有关。
- `c`函数实际上只跟随机串i有关。
- 两次`b`函数调用，其实也只跟d和i有关。

这样来看，函数其实也不复杂了。

那么，为什么说咱们不用管`c`呢？首先，我们知道i是完全随机生成的，既然是随机的，那么我随便造一个串当然也是合法的（只要字符都来自字符表）；其次，从函数上看，i是一个关键的密钥，它的定义不受制约，但是要返回的参数受到i的制约；而且`c`函数的调用只在确定  `enSecKey`的时候用到了，如果我们让i随机，我们不可避免地要设计RSA加密函数，这无疑增大了工作复杂度，这也不是编写爬虫要考虑的问题。再者，如果确定了i，`enSecKey`可以唯一确定，并且可以重复使用，让工作更加简单。

从功能上分析，i的作用应该相当于“临时密码”，对于同一个数据，只有每次请求都用完全随机的i加密，那些恶意分子才无法追踪用户的行踪；即便想，那也只有抓住i是多少，为此唯一的线索是`enSecKey`，但是众所周知RSA目前来看仍旧是无法破译的，只有计算机才知道密钥是多少。因此就实现了安全性控制。我们在写爬虫的时候，不需要考虑这样的安全问题，所以确定i是合理的。

那么我们重新运行一遍网页，从中仔细控制断点的步长，在**一趟**
加载中完成i和`enSecKey`的确定。
![确定i](/Python_Crawler_Practice-/proj3/imgs/step10.png)
## 3.代码的编写
现在，万事俱备，只剩东风，开始编写代码吧！

我们通过`Crypto`库完成AES加密函数的编写，注意AES的加密规范：要求字符串长度必须是16的整数倍，如果未满或者刚好16（视作长度为0），需要补齐，补齐的内容是：假定原始串长度是len,那么要填充的东西是`chr(16-len%16)`。

然后我们利用`b64encode`模块先对加密结果编码，之后才能进行utf8编码。

在调用我们的加密函数时，必须要先用`json.dumps`把data字典（即一个json对象）转化为字符串。



完成了函数的编写，之后发起请求，我们终于获取到了评论数据！
![获取到评论数据](/Python_Crawler_Practice-/proj3/imgs/see.png)
最终完成的程序可以参考：`4 实践：获取网易云的热评.py`。